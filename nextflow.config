// @Author   : Yang Liu
// @FileName : nextflow.config
// @Software : NANOME project
// @Organization : JAX Li Lab
// @Website  : https://github.com/TheJacksonLaboratory/nanome

params {
	// nanome running software env for Conda, Docker and Singularity
	conda_base_dir='/opt/conda'
	conda_name = "nanome"
	docker_name = "liuyangzzu/nanome:latest"
	singularity_name = "docker://liuyangzzu/nanome:latest"
	singularity_cache = 'local_singularity_cache'
	singularityBeforeScript = "module load singularity"

	tracedir = 'NANOME_trace'

	// process and executor configurations
	executor = false
	echo = false
	queueSize = 50

	// Default input params for pipeline running
	// dsname = 'TestData'
	// input = 'https://raw.githubusercontent.com/TheJacksonLaboratory/nanome/master/inputs/test.demo.filelist.txt'
	dsname = null
	input = null
	outputDir = "outputs"

	// Data type, can be human, ecoli, etc.
	dataType = "human"

	// slurm default parameters
	queueName = 'gpu'
	qosName = 'inference'
	jobMaxTime = '05:00:00'
	jobMaxMem = '32G'
	gresGPUOptions = '--gres=gpu:v100:1'

	// process default settings
	cacheStrategy = 'lenient'
	errorStrategy = 'terminate' // or 'ignore'

	// true if clean work dir when pipeline complete
	cleanCache = true // clean work dir after workflow finished
	cleanStep = true // clean after each process finished, optimize disk usage

	// number of processors for a task
	processors = 8

	// for compute intensive jobs, we use processors*times as multiprocessing options
	highProcTimes = 4
	mediumProcTimes = 2 // for normal process speedup, e.g., Tombo, Nanopolish, etc.
	lowProcTimes = 1 // for large memory process, e.g., megalodon, use conservative time 1 is reasonable
	reduceProcTimes = 1  // can be 0.5 for reduce the process, e.g., nanopolish, resquiggle, may set to 0.5 for large scale data

	cleanAnalyses = false // true if clean previous analysis in fast5 inputs
	//##################################################################
	//############### Reserved by tools default settings ###############
	//##################################################################
	//##################################################################
	// Default tool running configuration
	runNanopolish = true
	runMegalodon = true
	runDeepSignal = true
	runGuppy = true
	runTombo = true
	runDeepMod = true
	runResquiggle = true
	runCombine = true
	runMETEORE = true

	// Split tasks for two platform in JAX, true if only run GPU tasks
	filterGPUTaskRuns = false

	runBasecall = true
	runMethcall = true

	// if perform evaluations after callings
	outputQC = true // QC report for basecall
	outputIntermediate = false  // keep each batch outputs
	outputRaw = true // Raw combined outputs for each tool's format

	//======================================================
	//======================================================
	// Tools' specific additional options
	// Resquiggle specifications
	BasecallGroupName = "Basecall_1D_000" // Basecall ID name used by resquiggle
	BasecallSubGroupName = "BaseCalled_template"
	ResquiggleCorrectedGroup = "RawGenomeCorrected_000"
	tomboResquiggleOptions = ' ' // '--signal-length-range 0 500000  --sequence-length-range 0 50000', ref:  tombo resquiggle --print-advanced-arguments
	tomboMultiprocessRegionSize = 1000 // tombo methylation calling options

	// DeepSignal model
	DEEPSIGNAL_MODEL_TAR_GZ="model.CpG.R9.4_1D.human_hx1.bn17.sn360.v0.1.7+.tar.gz"
	DEEPSIGNAL_MODEL = 'model.CpG.R9.4_1D.human_hx1.bn17.sn360.v0.1.7+/bn_17.sn_360.epoch_9.ckpt'

	// DeepMod options
	// DeepMod default used model specifications
	DeepModGithub = "https://github.com/WGLab/DeepMod/archive/refs/tags/v0.1.3.tar.gz"
	DEEPMOD_RNN_MODEL = "rnn_conmodC_P100wd21_f7ne1u0_4/mod_train_conmodC_P100wd21_f3ne1u0"
	DEEPMOD_CLUSTER_MODEL = "na12878_cluster_train_mod-keep_prob0.7-nb25-chr1/Cg.cov5.nb25"
	useDeepModCluster = true
	moveOption = true // options of Guppy basecalled input for DeepMod, empty for Albacore usage
	chrSet = true //used by DeepMod, true is default, will use '  ' means all Human chromosomes, else need to specify such as chr1,chr2

	// Guppy model specificatoins
	guppyDir = ''
	// Suggested model by Guppy basecall
	GUPPY_BASECALL_MODEL = "dna_r9.4.1_450bps_hac.cfg"
	// Suggested model by Guppy methcall
	// GUPPY_METHCALL_MODEL="dna_r9.4.1_450bps_modbases_dam-dcm-cpg_hac.cfg" //  for Guppy v4.2.2
	GUPPY_METHCALL_MODEL = 'dna_r9.4.1_450bps_modbases_5mc_hac.cfg'

	// The suggested model and options by Megalodon
	MEGALODON_MODEL_FOR_GUPPY_CONFIG = "res_dna_r941_min_modbases_5mC_v001.cfg"
	GUPPY_TIMEOUT = 300
	READS_PER_GUPPY_BATCH = 100
	SAMTOOLS_PATH = "samtools"

	// METEORE Github
	METEOREGithub = "https://github.com/comprna/METEORE/archive/refs/tags/v1.0.0.tar.gz"
	METEORE_Dir = "METEORE-1.0.0"

	// Default online input used by pipeline, located in zenodo,
	// such as https://zenodo.org/record/5513090
	zenodoNumber="5513090"
	deepmod_ctar = "https://zenodo.org/record/${zenodoNumber}/files/C.tar.gz"
	genome_annotation = "https://zenodo.org/record/${zenodoNumber}/files/genome-annotation.tar.gz"
	reference_genome = "https://zenodo.org/record/${zenodoNumber}/files/hg38.tar.gz"
	// reference_genome = "https://zenodo.org/record/${zenodoNumber}/files/ecoli.tar.gz"
	deepsignal_model_tar = "https://zenodo.org/record/${zenodoNumber}/files/model.CpG.R9.4_1D.human_hx1.bn17.sn360.v0.1.7%2B.tar.gz"
	megalodon_model_tar = "https://zenodo.org/record/${zenodoNumber}/files/megalodon_model.tar.gz"

	//##################################################################
	//############### Reserved by google cloud computing ###############
	//##################################################################
	//##################################################################
	// Google cloud computing configurations defaults
	// used for google computing platform, ref: https://cloud.google.com/compute/docs/regions-zones#available
	// for exit code error info, ref: https://cloud.google.com/life-sciences/docs/troubleshooting#error_codes
	googleProjectName = 'jax-nanopore-01'
	googleLocation = 'us'
	googleRegion = 'us-east1'
	bootDiskSizeCloud = 20.GB
	preemptibleCloud = true // save costs using preemptible way
	networkCloud = 'default'
	subnetworkCloud = 'default'

	maxRetries = 5

	machineType = "n1-standard-8" // or "n1-highmem-16", ref: https://cloud.google.com/compute/docs/general-purpose-machines#n1-shared-core
	gpuType = 'nvidia-tesla-p100' // lower price than v100, ref: https://cloud.google.com/compute/gpus-pricing
	gpuNumber = 1
	highmemMachineType = "n1-highmem-16"  // n1-highmem-16 16 104, n1-standard-8 8 30

	lowDiskSize = 100.GB // for test and check
	midDiskSize = 150.GB // for methylation
	highDiskSize = 200.GB // for untar, basecall and resquiggle

	// Lifebit cloudOS configurations start here
	// Lifebit cloudOS default config
	config = 'conf/executors/lifebit.config'

	//##################################################################
	//########################### End of block #########################
	//##################################################################
	//##################################################################
}

// Running on different platforms
profiles {
	// need by Lifebit CloudOS
	standard { includeConfig params.config }

	ci { includeConfig 'conf/examples/ci.config' }

	ci_human { includeConfig 'conf/examples/ci_human.config' }

	conda {
		process.conda = params.conda_name
	}

	docker {
		process.container = params.docker_name
		// process.containerOptions = params.containerOptions
		docker{
			enabled = true
			// runOptions = params.containerOptions // pass CUDA var to process for docker container, --gpus all, ref:https://docs.docker.com/engine/reference/commandline/run/
			// temp = 'auto'
			envWhitelist = 'CUDA_VISIBLE_DEVICES' // Ref: https://www.nextflow.io/docs/latest/config.html#scope-docker
		}
	}

	singularity {
		process {
			container = params.singularity_name
			//beforeScript = "module load singularity"
		}

		singularity {
			enabled = true
			autoMounts = true
			cacheDir = params.singularity_cache
			envWhitelist = 'CUDA_VISIBLE_DEVICES' // Ref: https://github.com/nextflow-io/nextflow/issues/776
		}
	}

	hpc {
		process {
			executor = 'slurm'
			queue = params.queueName
			clusterOptions = "-q ${params.qosName} -n ${params.processors}  ${params.gresGPUOptions == false ? ' ' : params.gresGPUOptions} --time=${params.jobMaxTime} --mem=${params.jobMaxMem}"
		}
	}

	// Google cloud computing platform
	google {
		params{ //overide default params for GCP
			errorStrategy = 'ignore'
		}
		executor {
			name = 'google-lifesciences'
			pollInterval = '30 sec'
		}

		google {
			project = params.googleProjectName
			// use region instead of zone, a region contains many zones: zone = 'us-east1-c'
			region = params.googleRegion
			location = params.googleLocation
			lifeSciences.debug = true
			lifeSciences.preemptible = params.preemptibleCloud
			lifeSciences.usePrivateAddress = false
			lifeSciences.sshDaemon = true
			lifeSciences.bootDiskSize = params.bootDiskSizeCloud
			enableRequesterPaysBuckets = true
			lifeSciences.network = params.networkCloud
			lifeSciences.subnetwork = params.subnetworkCloud
		}

		// Include nanome input from google cloud params
		// includeConfig 'conf/gc_params.config'
		process {
			// Machine types ref: https://cloud.google.com/solutions/sql-server-performance-tuning-compute-engine.pdf?hl=en
			machineType = params.machineType
			disk = params.midDiskSize
			maxRetries = params.maxRetries
			echo = params.echo
			// Ref: https://cloud.google.com/life-sciences/docs/troubleshooting
			errorStrategy = {task.attempt == process.maxRetries ? params.errorStrategy :  task.exitStatus in [10, 14] ? 'retry' : params.errorStrategy }

			withName: 'Megalodon|Resquiggle|DeepSignal|DeepMod' { // allocate highmem machine type, if facing large data
				machineType = params.highmemMachineType
			}

			withName: 'EnvCheck|Basecall|Guppy|Megalodon' { // allocate gpu
				accelerator = [request:  params.gpuNumber, type: params.gpuType]
				beforeScript = "export CUDA_VISIBLE_DEVICES=0" // pass CUDA var to process, since GCP do not export it
			}

			withName: 'Untar|Basecall|Guppy|Resquiggle' { // allocate high disk size
				disk = params.highDiskSize
			}
		}
	}
}

env {
	PATH = params.guppyDir.equals('') ? '$PATH':["${params.guppyDir}/bin", '$PATH'].join(':')
	numProcessor = "${params.processors}"
}

process {
	cache = params.cacheStrategy
	errorStrategy = params.errorStrategy
	echo = params.echo
}

executor {
	name = params.executor
	queueSize = params.queueSize
}

dag {
  file = "${params.tracedir}/NANOME_pipeline_dag_${params.dsname}.svg"
}

report {
  file = "${params.tracedir}/NANOME_report_${params.dsname}.html"
}

timeline {
  file = "${params.tracedir}/NANOME_timeline_${params.dsname}.html"
}

trace {
  file = "${params.tracedir}/NANOME_trace_${params.dsname}.txt"
}

manifest {
	homePage = 'https://github.com/TheJacksonLaboratory/nanome'
	description = 'NANOME (Nanopore methylation) pipeline for DNA methylation calling'
	mainScript = 'main.nf'
	version = '1.3.4'
}
